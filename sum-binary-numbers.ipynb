{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum of two binary numbers using single cell RNN\n",
    "\n",
    "Martin Kersner, <m.kersner@gmail.com>\n",
    "\n",
    "2017/07/04\n",
    "\n",
    "This notebook is part of presentation about Recurrent Neural Networks at [Seoul Artificial Intelligence Meetup](https://www.meetup.com/Seoul-Artificial-Intelligence-Meetup/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary functions for conversion to/from binary numbers and for generating and splitting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def int2bin(i, length=10):\n",
    "    b = bin(i)[2:].zfill(length)\n",
    "    b_lst = [int(i) for i in b]\n",
    "    b_lst.reverse()\n",
    "    return np.array(b_lst)\n",
    "\n",
    "def bin2int(b, axis=0):\n",
    "    b_lst = list(b[0,:,axis])\n",
    "    b_lst.reverse()\n",
    "    b_str = \"\".join(str(int(i)) for i in b_lst)\n",
    "    return int(b_str, 2)\n",
    "\n",
    "def int2binABC(A, B, C, length=10):\n",
    "    return int2bin(A, length), int2bin(B, length), int2bin(C, length)\n",
    "\n",
    "def gen_data(func):\n",
    "    def inner(*args, **kwargs):\n",
    "        A, B = func(*args, **kwargs)\n",
    "        C = A+B\n",
    "        Ab, Bb, Cb = int2binABC(A, B, C)\n",
    "\n",
    "        X_batch = None\n",
    "        X_batch = np.vstack((Ab, Bb)).T\n",
    "        X_batch = X_batch[np.newaxis, :]\n",
    "        Y_batch = Cb[np.newaxis, :, np.newaxis]\n",
    "        \n",
    "        return X_batch, Y_batch\n",
    "    \n",
    "    return inner\n",
    "\n",
    "@gen_data\n",
    "def gen_given_data(A, B):\n",
    "    return A, B\n",
    "\n",
    "@gen_data\n",
    "def gen_random_data(max_val=100):\n",
    "    A = np.random.randint(max_val)\n",
    "    B = np.random.randint(max_val)\n",
    "    \n",
    "    return A, B\n",
    "\n",
    "def gen_dataset(length, binary_length=10):\n",
    "    X = np.zeros((length*length, binary_length,  2))\n",
    "    Y = np.zeros((length*length, binary_length, 1))    \n",
    "\n",
    "    idx = 0\n",
    "    for A in range(length):\n",
    "        for B in range(length):\n",
    "            C = A + B\n",
    "\n",
    "            Ab, Bb, Cb = int2binABC(A, B, C, binary_length)\n",
    "\n",
    "            X[idx] = np.vstack((Ab, Bb)).T\n",
    "            Y[idx] = Cb[:, np.newaxis]\n",
    "\n",
    "            idx += 1\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def split_train_test(X, Y, ratio=0.7):\n",
    "    length = X.shape[0]\n",
    "    \n",
    "    ran = range(length)\n",
    "    train_lst = random.sample(ran, int(ratio*length))\n",
    "    test_lst = list(set(ran)-set(train_lst))\n",
    "    \n",
    "    X_train = X[train_lst, :, :]\n",
    "    Y_train = Y[train_lst, :, :]\n",
    "    \n",
    "    X_test = X[test_lst, :, :]\n",
    "    Y_test = Y[test_lst, :, :]\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset\n",
    "\n",
    "Dataset consist of numbers between 0 and 99 (`X_data`) and their sums (`Y_data`). Dataset is split to training and validation data in ratio 10:90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data, Y_data = gen_dataset(100)\n",
    "X_train, Y_train, X_test, Y_test = split_train_test(X_data, Y_data, 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0])\n",
    "print(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define RNN network\n",
    "\n",
    "RNN network is composed of 1 one RNN cell with 2 neurons and will be computed over 10 time steps.\n",
    "\n",
    "Number of inputs is 2; one value for the first binary number and one for the second binary numnber.\n",
    "Number of outputs is 1, because we want to predict 1 binary value per time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps   = 10\n",
    "n_inputs  = 2\n",
    "n_outputs = 1\n",
    "n_neurons = 2\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "\n",
    "# RNN cell\n",
    "cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "    tf.contrib.rnn.BasicRNNCell(num_units=n_neurons),\n",
    "    output_size=n_outputs)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "loss = tf.reduce_mean(tf.square(outputs-y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate\n",
    "\n",
    "Train model for 80 epochs or terminate training early if MSE drops below 0.01. Traning data are fed in batches of size 50. After, trained model is evaluated on validation dataset and saved into `model` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 MSE: 0.4649597108364105\n",
      "epoch 1 MSE: 0.3353145122528076\n",
      "epoch 2 MSE: 0.277487576007843\n",
      "epoch 3 MSE: 0.25327014923095703\n",
      "epoch 4 MSE: 0.24150414764881134\n",
      "epoch 5 MSE: 0.23641417920589447\n",
      "epoch 6 MSE: 0.23250973224639893\n",
      "epoch 7 MSE: 0.22827669978141785\n",
      "epoch 8 MSE: 0.22414745390415192\n",
      "epoch 9 MSE: 0.2203630954027176\n",
      "epoch 10 MSE: 0.21682028472423553\n",
      "epoch 11 MSE: 0.21336780488491058\n",
      "epoch 12 MSE: 0.20991644263267517\n",
      "epoch 13 MSE: 0.20639681816101074\n",
      "epoch 14 MSE: 0.2027425915002823\n",
      "epoch 15 MSE: 0.19890856742858887\n",
      "epoch 16 MSE: 0.19487206637859344\n",
      "epoch 17 MSE: 0.19062311947345734\n",
      "epoch 18 MSE: 0.1861514002084732\n",
      "epoch 19 MSE: 0.18143562972545624\n",
      "epoch 20 MSE: 0.17644280195236206\n",
      "epoch 21 MSE: 0.1711369901895523\n",
      "epoch 22 MSE: 0.16548380255699158\n",
      "epoch 23 MSE: 0.1594487875699997\n",
      "epoch 24 MSE: 0.1530078500509262\n",
      "epoch 25 MSE: 0.14618070423603058\n",
      "epoch 26 MSE: 0.139068141579628\n",
      "epoch 27 MSE: 0.13186581432819366\n",
      "epoch 28 MSE: 0.12483739107847214\n",
      "epoch 29 MSE: 0.11825453490018845\n",
      "epoch 30 MSE: 0.11233153939247131\n",
      "epoch 31 MSE: 0.10718227922916412\n",
      "epoch 32 MSE: 0.10281109809875488\n",
      "epoch 33 MSE: 0.09913578629493713\n",
      "epoch 34 MSE: 0.09602654725313187\n",
      "epoch 35 MSE: 0.09334349632263184\n",
      "epoch 36 MSE: 0.09096168726682663\n",
      "epoch 37 MSE: 0.0887816920876503\n",
      "epoch 38 MSE: 0.0867295041680336\n",
      "epoch 39 MSE: 0.08475172519683838\n",
      "epoch 40 MSE: 0.08281094580888748\n",
      "epoch 41 MSE: 0.08088281750679016\n",
      "epoch 42 MSE: 0.07895505428314209\n",
      "epoch 43 MSE: 0.07702618092298508\n",
      "epoch 44 MSE: 0.07510307431221008\n",
      "epoch 45 MSE: 0.07319606840610504\n",
      "epoch 46 MSE: 0.07131461799144745\n",
      "epoch 47 MSE: 0.06946588307619095\n",
      "epoch 48 MSE: 0.06765587627887726\n",
      "epoch 49 MSE: 0.06589043140411377\n",
      "epoch 50 MSE: 0.06417407840490341\n",
      "epoch 51 MSE: 0.06250868737697601\n",
      "epoch 52 MSE: 0.06089310348033905\n",
      "epoch 53 MSE: 0.05932335928082466\n",
      "epoch 54 MSE: 0.057793229818344116\n",
      "epoch 55 MSE: 0.05629450082778931\n",
      "epoch 56 MSE: 0.05481726676225662\n",
      "epoch 57 MSE: 0.05334986001253128\n",
      "epoch 58 MSE: 0.051879070699214935\n",
      "epoch 59 MSE: 0.05038994550704956\n",
      "epoch 60 MSE: 0.04886515066027641\n",
      "epoch 61 MSE: 0.04728441685438156\n",
      "epoch 62 MSE: 0.0456242710351944\n",
      "epoch 63 MSE: 0.043858934193849564\n",
      "epoch 64 MSE: 0.04196220263838768\n",
      "epoch 65 MSE: 0.03991106152534485\n",
      "epoch 66 MSE: 0.03769164904952049\n",
      "epoch 67 MSE: 0.03530886396765709\n",
      "epoch 68 MSE: 0.032796453684568405\n",
      "epoch 69 MSE: 0.03022279404103756\n",
      "epoch 70 MSE: 0.027685409411787987\n",
      "epoch 71 MSE: 0.025291267782449722\n",
      "epoch 72 MSE: 0.023128120228648186\n",
      "epoch 73 MSE: 0.02124372497200966\n",
      "epoch 74 MSE: 0.019647518172860146\n",
      "epoch 75 MSE: 0.01832438074052334\n",
      "epoch 76 MSE: 0.017245449125766754\n",
      "epoch 77 MSE: 0.016374537721276283\n",
      "epoch 78 MSE: 0.015672054141759872\n",
      "epoch 79 MSE: 0.015103369951248169\n",
      "test  MSE:  0.0154997\n"
     ]
    }
   ],
   "source": [
    "batch_size   = 50\n",
    "n_epochs     = 80\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(X_train.shape[0] // batch_size):\n",
    "            X_batch = X_train[iteration*batch_size:(iteration*batch_size)+batch_size,:,:]\n",
    "            Y_batch = Y_train[iteration*batch_size:(iteration*batch_size)+batch_size,:,:]\n",
    "        \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: Y_batch})\n",
    "\n",
    "        mse = loss.eval(feed_dict={X: X_batch, y: Y_batch})\n",
    "        print(\"epoch {} MSE: {}\".format(epoch, mse))\n",
    "        \n",
    "        if mse < 0.01:\n",
    "            break\n",
    "\n",
    "    saver.save(sess, \"./model\")\n",
    "    \n",
    "    res = loss.eval(feed_dict={X: X_test, y: Y_test})\n",
    "    print(\"test  MSE: \", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "\n",
    "Load trained model and compute sum of A and B binary numbers.\n",
    "\n",
    "Change `A` and `B` values and see if sum of those numbers will be correct.\n",
    "`A` and `B` values are internally converted to binary numbers with **rightmost significant  bit**.\n",
    "Notice that model was trained only on numbers up to 99, but is able to sum larger numbers if their total sum is smaller than 1023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "A    853\n",
      "B    126\n",
      "SUM  979\n",
      "Correct\n"
     ]
    }
   ],
   "source": [
    "A = 853\n",
    "B = 126\n",
    "C = A+B\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./model\")\n",
    "      \n",
    "    X_batch, y_batch = gen_given_data(A, B)\n",
    "    \n",
    "    binary_sum = outputs.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "    \n",
    "    # Thresholding is neccessary because predictions from model are floating point values between 0 and 1\n",
    "    # but we want to obtain binary values.\n",
    "    binary_sum[binary_sum > 0.5]  = 1\n",
    "    binary_sum[binary_sum <= 0.5] = 0\n",
    "    \n",
    "    int_sum = bin2int(binary_sum)\n",
    "    \n",
    "    print(\"A   \", bin2int(X_batch))\n",
    "    print(\"B   \", bin2int(X_batch, axis=1))\n",
    "    print(\"SUM \", int_sum)\n",
    "    \n",
    "    print(\"Correct\" if C == int_sum else \"Wrong\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
